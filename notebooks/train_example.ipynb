{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7781627a",
   "metadata": {},
   "source": [
    "# Model Training Example\n",
    "\n",
    "This notebook demonstrates how to train a neural network on using PyTorch Lightning for learning purposes. For small models or datasets this might be fine but for large scale projects you should be using train.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57bef3",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')  # Add parent directory to path for imports\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from datamodule import LazyDataModule\n",
    "from model import MLPLightningModule, MLP\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "pl.seed_everything(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21c7ebe",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b16b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "args = {\n",
    "    # Data\n",
    "    \"train_files\": \"/path/to/your/data\",  # TODO: Update this path\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 4,\n",
    "    \n",
    "    # Model\n",
    "    \"in_channels\": 10,  # TODO: Adjust based on your input features\n",
    "    \"out_channels\": 1,  # TODO: Adjust based on your target\n",
    "    \"hidden_dims\": [64, 128, 64],\n",
    "    \n",
    "    # Training\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"max_epochs\": 50,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # Output\n",
    "    \"output_dir\": \"../outputs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0aa75",
   "metadata": {},
   "source": [
    "## 3. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946298de",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(args[\"output_dir\"])\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize data module\n",
    "datamodule = LazyDataModule(\n",
    "    train_files=args[\"train_files\"],\n",
    "    batch_size=args[\"batch_size\"],\n",
    "    num_workers=args[\"num_workers\"],\n",
    "    seed=args[\"seed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a3e30",
   "metadata": {},
   "source": [
    "## 4. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = MLP(\n",
    "    in_channels=args[\"in_channels\"],\n",
    "    out_channels=args[\"out_channels\"],\n",
    ")\n",
    "\n",
    "# Wrap in Lightning module\n",
    "lightning_module = MLPLightningModule(\n",
    "    model=model,\n",
    "    learning_rate=args[\"learning_rate\"],\n",
    ")\n",
    "\n",
    "# Set up callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=output_dir / \"checkpoints\",\n",
    "        filename=\"mlp-{epoch:02d}-{val_loss:.4f}\",\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=3,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "]\n",
    "\n",
    "# Set up logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=output_dir,\n",
    "    name=\"logs\",\n",
    ")  # we could also use wandb: https://wandb.ai/home\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=args[\"max_epochs\"],\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfaced0",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(lightning_module, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82912e1",
   "metadata": {},
   "source": [
    "## 8. Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c400aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model manually\n",
    "torch.save(lightning_module.state_dict(), \"model_weights.pt\")\n",
    "\n",
    "# Load model\n",
    "# loaded_model = LazyLightningModule.load_from_checkpoint(\"checkpoints/best_model.ckpt\", model=model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
